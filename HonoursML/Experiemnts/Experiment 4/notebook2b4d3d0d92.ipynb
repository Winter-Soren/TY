{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade pip\n# !pip install pandas-profiling\n# !pip install pandas-profiling[notebook]\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom datetime import datetime\n\ndf=pd.read_csv('/kaggle/input/consumercomplaintsdata/Consumer_Complaints.csv')\ndf.columns = df.columns.str.title()\ndf['Date'] =pd.to_datetime(df['Date Received'])\ne_df=pd.DataFrame().from_records([{\"empty_prec\":np.round(len(df[df[col].isna()])/len(df), 4)*100, \"col\":col} for col in df.columns])\nprint(e_df)\nprint(\"Dropping Columns with high empty ratio, >60%\")\nprint(e_df[e_df[\"empty_prec\"]>60])\ndf=df.drop(e_df[e_df[\"empty_prec\"]>60].col.values, axis=1)\ndf['Sub-Product']=df['Sub-Product'].fillna(\"Unknown\")\ndf.dropna(subset=['State', 'Zip Code'], inplace=True)\nmode_value = df['Consumer Disputed?'].mode().values[0]\ndf['Consumer Disputed?'].fillna(mode_value, inplace = True)\ndf['Consumer Disputed?'].isnull().fillna(mode_value, inplace = True)\ndf['Year'] =df['Date'].dt.year\ndf['Month'] =df['Date'].dt.month\ndf['Week_Days'] = df['Date'].dt.day_name()\nissue_groups={}\nproduct_groups={}\n\nfor issue, group in df.groupby('Issue'):\n    mode=group['Sub-Issue'].mode()\n    issue_groups[issue]=mode.values[0] if len(mode) else 'NA'\ndf['Sub-Issue'].fillna('Unknown', inplace=True)\ndf['Sub-Issue'] = df.apply(lambda x: issue_groups[x['Issue']] if x['Sub-Issue']=='Unknown' else x['Sub-Issue'], axis=1)\n\n\nfor product, group in df.groupby('Product'):\n    mode=group['Sub-Product'].mode()\n    product_groups[product]=mode.values[0] if len(mode) else 'NA'\ndf['Sub-Product'].fillna('Unknown', inplace=True)\ndf['Sub-Product'] = df.apply(lambda x: product_groups[x['Product']] if x['Sub-Product']=='Unknown' else x['Sub-Product'], axis=1)\n\nu_df=pd.DataFrame().from_records([{\"unique_prec\":np.round(len(df[col].unique())/len(df), 4)*100, \"col\":col} for col in df.columns])\nprint(\"Dropping Columns with high Uniqueness ratio, >50%\")\nprint(u_df[u_df[\"unique_prec\"]>50])\ndf.drop(u_df[u_df[\"unique_prec\"]>50].col.values, axis=1, inplace=True)\n\nc_df=pd.DataFrame(df['Company'].value_counts()).reset_index().reset_index()\nn=1000\nprint(\"Dropping Company Values with less than %d complaints, keeping %f%% values, dropping %f%% values\"% (n, c_df[c_df['Company']>=n]['Company'].sum()/len(df), c_df[c_df['Company']<n]['Company'].sum()/len(df)))\ndf=df[df['Company'].isin(c_df[c_df['Company']>=n]['index'].values)]\nprint(\"Left with %d Companies\"%len(df.Company.unique()))\n\nprint(\"Cleaned Data set, Empty Ratios: \\n\", pd.DataFrame().from_records([{\"empty_prec\":np.round(len(df[df[col].isna()])/len(df), 4)*100, \"col\":col} for col in df.columns]))\nprint(\"Cleaned Data set, Empty Ratios: \\n\", pd.DataFrame().from_records([{\"unique_prec\":np.round(len(df[col].unique())/len(df), 4)*100, \"col\":col} for col in df.columns]))\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h, w = 4, 3\n_, ax=plt.subplots(h,w, figsize=(w*10,h*7))\ntop_n=10\ndf['Product'].value_counts().sort_values(ascending=False)[:top_n].to_frame('counts').sort_values('counts', ascending=True).plot.barh(title='Top Complaints in Products', ax=ax[0][0])\ndf['Sub-Product'].value_counts().sort_values(ascending=False)[:top_n].to_frame('counts').sort_values('counts', ascending=True).plot.barh(title='Top Complaints in Sub Products', ax=ax[0][1])\ndf['Company'].value_counts().sort_values(ascending=False)[:top_n].to_frame('counts').sort_values('counts', ascending=True).plot.barh(title='Top 20 Companies with Highest number of Compaints', ax=ax[0][2])\ndf['Timely Response?'].value_counts().plot.pie(ax=ax[1][0])\ndf['Company Response To Consumer'].fillna('NA').value_counts().plot.pie(ax=ax[1][1])\ndf['Issue'].value_counts().sort_values(ascending=False)[:top_n].to_frame('counts').sort_values('counts', ascending=True).plot.barh(title='Top 20 Issues with Highest number of Compaints', ax=ax[1][2])\ndf['Sub-Issue'].value_counts().sort_values(ascending=False)[:top_n].to_frame('counts').sort_values('counts', ascending=True).plot.barh(title='Top 20 Sub-Issues with Highest number of Compaints', ax=ax[2][0])\ndf['Submitted Via'].value_counts().plot.pie(title=\"Platform of Complaint\", legend=False, ax=ax[2][1])\ndf['Consumer Disputed?'].value_counts().plot.pie(title=\"Is Consumer Disputed\", legend=False, ax=ax[2][2])\ndf.groupby(['Month']).size().plot.bar(title=\"Complaints by Month\", legend=False, ax=ax[3][0])\ndf.groupby(['Year']).size().plot(title=\"Complaints by Year\", legend=False, ax=ax[3][1])\ntop_banks=df['Company'].value_counts().sort_values(ascending=False)[:top_n].index\ndf[df['Company'].isin(top_banks)].groupby(['Year', 'Company']).size().unstack().plot(ax=ax[3][2], marker='^', title='Complaints against companies over years')\n\nplt.tight_layout()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_df=pd.DataFrame().from_records([{\"n_unique\":len(df[col].unique()), \"unique_prec\":np.round(len(df[col].unique())/len(df), 4)*100, \"col\":col} for col in df.columns])\nu_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=['Product', 'Sub-Product', 'Issue', 'Sub-Issue',\n       'Company', 'State', 'Submitted Via',\n       'Company Response To Consumer',\n       'Timely Response?', 'Consumer Disputed?']\n\nfor col in cols:\n    df[col]=df[col].astype('category')\n\nv_df=pd.get_dummies(df[cols], columns=cols)\n# v_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nmodel=KMeans(n_clusters=5, random_state=0,)\nkmeans=model.fit(v_df.values)\ndf['clusters']=kmeans.labels_\n\ndf.clusters.value_counts().plot.pie(title=\"Distribution of cases by cluster\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax=plt.subplots(5, figsize=(10,20))\nn=10\nfor i in range(5):\n    df[df['clusters']==i].Issue.value_counts()[:n].sort_values().plot.barh(ax=ax[i], title=\"Top 10 Topic of issues in Cluster %d\"%i)\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors=v_df.values\ndistances=[]\nfor i, (vector, label) in enumerate(zip(vectors, kmeans.labels_)):\n#     print(label, kmeans.cluster_centers_[label])\n    distances+=[{\"label\":label, \"dist\":np.linalg.norm(vector - kmeans.cluster_centers_[label])}]\n    \nd_df=pd.DataFrame().from_records(distances)\nfig, ax1=plt.subplots(5, figsize=(20,20), sharex=True)\navg_score=d_df['dist'].mean()\nfor label, group in d_df.groupby('label'):\n    \n    ax1[label].axvline(avg_score, linestyle='--', linewidth=2, color='green')\n    ax1[label].set_yticks([])\n    ax1[label].set_xlim([1.5, 3])\n    ax1[label].set_xlabel('Distance from center')\n    ax1[label].set_ylabel('Cluster labels')\n    ax1[label].set_title('Distance from centers for label %d'%label, y=1.02)\n    group[:100].sort_values('dist').plot.barh(x='label', y='dist', linewidth=.1, ax=ax1[label], edgecolor='none')\n\nplt.tight_layout()\nd_df.groupby('label').agg({\"dist\":[\"min\", \"max\", \"std\", \"mean\"]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}